{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dd03681-2a78-439c-afe8-e49484788cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d974fb97-a285-442a-96f0-4dd063d6899e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RNN...\n",
      "Epoch 0, Loss: 1.3861\n",
      "Epoch 10, Loss: 1.3848\n",
      "Epoch 20, Loss: 1.3735\n",
      "Epoch 30, Loss: 1.2724\n",
      "Epoch 40, Loss: 0.7537\n",
      "Epoch 50, Loss: 0.2660\n",
      "Epoch 60, Loss: 0.1254\n",
      "Epoch 70, Loss: 0.0771\n",
      "Epoch 80, Loss: 0.0545\n",
      "Epoch 90, Loss: 0.0417\n",
      "Input Sequence: ['I', 'am', 'very']\n",
      "Predicted Word: happy\n",
      "Actual Word: happy\n"
     ]
    }
   ],
   "source": [
    "words = [\"I\", \"am\", \"very\", \"happy\"]\n",
    "vocab_size = len(words)\n",
    "hidden_size = 3\n",
    "input_sequence = words[:3]\n",
    "target_word = words[3]\n",
    "\n",
    "word_to_index = {word: i for i, word in enumerate(words)}\n",
    "one_hot = {word: np.zeros(vocab_size) for word in words}\n",
    "for word in one_hot:\n",
    "    one_hot[word][word_to_index[word]] = 1\n",
    "\n",
    "np.random.seed(42)\n",
    "Wx = np.random.randn(hidden_size, vocab_size) * 0.01\n",
    "Wh = np.random.randn(hidden_size, hidden_size) * 0.01\n",
    "Wy = np.random.randn(vocab_size, hidden_size) * 0.01\n",
    "\n",
    "def forward_propagation(inputs, h_prev):\n",
    "    xs, hs, ats, ys = {}, {}, {}, {}\n",
    "    hs[-1] = np.copy(h_prev)\n",
    "\n",
    "    for t in range(len(inputs)):\n",
    "        xs[t] = one_hot[inputs[t]].reshape(vocab_size, 1)\n",
    "        ats[t] = np.dot(Wh, hs[t-1]) + np.dot(Wx, xs[t])\n",
    "        hs[t] = np.tanh(ats[t])\n",
    "        ys[t] = np.dot(Wy, hs[t])\n",
    "        ys[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t]))\n",
    "\n",
    "    return xs, hs, ats, ys\n",
    "\n",
    "def compute_loss(ys, target):\n",
    "    target_idx = word_to_index[target]\n",
    "    loss = -np.log(ys[len(ys)-1][target_idx, 0])\n",
    "    return loss\n",
    "\n",
    "def backward_propagation(xs, hs, ats, ys, target):\n",
    "    dWx, dWh, dWy = np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(Wy)\n",
    "    dh_next = np.zeros((hidden_size, 1))\n",
    "\n",
    "    target_idx = word_to_index[target]\n",
    "    dy = np.copy(ys[len(ys)-1])\n",
    "    dy[target_idx] -= 1\n",
    "\n",
    "    for t in reversed(range(len(xs))):\n",
    "        dWy += np.dot(dy, hs[t].T)\n",
    "        dh = np.dot(Wy.T, dy) + dh_next\n",
    "        dh_raw = (1 - hs[t] * hs[t]) * dh\n",
    "        dWx += np.dot(dh_raw, xs[t].T)\n",
    "        if t > 0:\n",
    "            dWh += np.dot(dh_raw, hs[t-1].T)\n",
    "        dh_next = np.dot(Wh.T, dh_raw)\n",
    "\n",
    "        if t < len(xs) - 1:\n",
    "            dy = np.zeros_like(dy)\n",
    "\n",
    "    for dparam in [dWx, dWh, dWy]:\n",
    "        np.clip(dparam, -5, 5, out=dparam)\n",
    "\n",
    "    return dWx, dWh, dWy\n",
    "\n",
    "def train(inputs, target, epochs=100, learning_rate=0.1):\n",
    "    global Wx, Wh, Wy\n",
    "    h_prev = np.zeros((hidden_size, 1))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        xs, hs, ats, ys = forward_propagation(inputs, h_prev)\n",
    "        loss = compute_loss(ys, target)\n",
    "        dWx, dWh, dWy = backward_propagation(xs, hs, ats, ys, target)\n",
    "\n",
    "        Wx -= learning_rate * dWx\n",
    "        Wh -= learning_rate * dWh\n",
    "        Wy -= learning_rate * dWy\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "    return ys\n",
    "\n",
    "def predict(inputs):\n",
    "    h_prev = np.zeros((hidden_size, 1))\n",
    "    xs, hs, ats, ys = forward_propagation(inputs, h_prev)\n",
    "    last_y = ys[len(inputs)-1]\n",
    "    predicted_idx = np.argmax(last_y)\n",
    "    return words[predicted_idx]\n",
    "\n",
    "print(\"Training RNN...\")\n",
    "ys = train(input_sequence, target_word, epochs=100, learning_rate=0.1)\n",
    "predicted_word = predict(input_sequence)\n",
    "print(f\"Input Sequence: {input_sequence}\")\n",
    "print(f\"Predicted Word: {predicted_word}\")\n",
    "print(f\"Actual Word: {target_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6cb4c7-983c-4fe1-942f-eb3b0c0341dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
